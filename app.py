"""
GCMC/QBC Link Visualizer with Ahrefs Integration
Streamlit App
"""
import streamlit as st
import json
import pandas as pd
import plotly.graph_objects as go
import networkx as nx
from pathlib import Path

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Link Visualizer - GCMC/QBC",
    page_icon="ğŸ”—",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-title {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-size: 3em;
        font-weight: 700;
        text-align: center;
        margin-bottom: 10px;
    }
    .subtitle {
        text-align: center;
        color: #6c757d;
        font-size: 1.2em;
        margin-bottom: 30px;
    }
    .stat-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 20px;
        border-radius: 10px;
        text-align: center;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .keyword-badge {
        display: inline-block;
        padding: 4px 12px;
        margin: 4px;
        border-radius: 20px;
        font-size: 0.85em;
        font-weight: 600;
    }
    .rank-1-10 {
        background: #e8f5e9;
        color: #2e7d32;
        border: 2px solid #4caf50;
    }
    .rank-11-20 {
        background: #fff3e0;
        color: #e65100;
        border: 2px solid #ff9800;
    }
</style>
""", unsafe_allow_html=True)

# ã‚¿ã‚¤ãƒˆãƒ«
st.markdown('<h1 class="main-title">ğŸ”— Link Visualizer</h1>', unsafe_allow_html=True)
st.markdown('<p class="subtitle">GCMC & QBC å†…éƒ¨ãƒªãƒ³ã‚¯æ§‹é€  + Ahrefsãƒ‡ãƒ¼ã‚¿çµ±åˆ</p>', unsafe_allow_html=True)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.header("âš™ï¸ è¨­å®š")

# ãƒ‰ãƒ¡ã‚¤ãƒ³é¸æŠ
domain = st.sidebar.radio(
    "ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’é¸æŠ",
    ["GCMC", "QBC"],
    help="åˆ†æã™ã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’é¸æŠã—ã¦ãã ã•ã„"
)

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
@st.cache_data
def load_data(domain):
    """JSONãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    # çµ¶å¯¾ãƒ‘ã‚¹ã‚’ä½¿ç”¨ï¼ˆStreamlit Cloudå¯¾å¿œï¼‰
    import os
    base_dir = Path(__file__).parent
    
    file_map = {
        "GCMC": base_dir / "GCMC" / "gcmc_link_analysis_report.json",
        "QBC": base_dir / "QBC" / "qbc_link_analysis_report.json"
    }
    
    file_path = file_map[domain]
    if not file_path.exists():
        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        st.info(f"ğŸ“ ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}")
        st.info(f"ğŸ“‚ æ¢ã—ã¦ã„ã‚‹ãƒ‘ã‚¹: {file_path}")
        return None
    
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

data = load_data(domain)

if data is None:
    st.stop()

# Ahrefsãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“Š Ahrefsãƒ‡ãƒ¼ã‚¿")
uploaded_file = st.sidebar.file_uploader(
    "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=['csv'],
    help="Ahrefsã‹ã‚‰ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿"
)

# Ahrefsãƒ‡ãƒ¼ã‚¿è§£æ
ahrefs_data = {}
if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        required_cols = ['Keyword', 'Current URL', 'Current position', 'Volume']
        
        if all(col in df.columns for col in required_cols):
            # 20ä½ä»¥å†…ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            df_filtered = df[df['Current position'] <= 20].copy()
            
            # URLã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            for url, group in df_filtered.groupby('Current URL'):
                ahrefs_data[url] = group.sort_values('Volume', ascending=False)[
                    ['Keyword', 'Current position', 'Volume']
                ].to_dict('records')
            
            st.sidebar.success(f"âœ… {len(ahrefs_data)} ãƒšãƒ¼ã‚¸ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        else:
            st.sidebar.error("âŒ å¿…è¦ãªã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    except Exception as e:
        st.sidebar.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")

# ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")

page_type_filter = st.sidebar.multiselect(
    "ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—",
    ["monetization", "feeder", "hybrid"],
    default=["monetization", "feeder", "hybrid"],
    format_func=lambda x: {"monetization": "åç›ŠåŒ–", "feeder": "ãƒ•ã‚£ãƒ¼ãƒ€ãƒ¼", "hybrid": "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰"}[x]
)

# æ¤œç´¢
search_query = st.sidebar.text_input("ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢", placeholder="URLã‚„ã‚¿ã‚¤ãƒˆãƒ«ã§æ¤œç´¢...")

# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
filtered_pages = [
    p for p in data['pages']
    if p['type'] in page_type_filter
    and (not search_query or 
         search_query.lower() in p['url'].lower() or
         search_query.lower() in p.get('title', p.get('h1', '')).lower())
]

# çµ±è¨ˆæƒ…å ±
st.header("ğŸ“Š ã‚µãƒãƒªãƒ¼çµ±è¨ˆ")
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("ç·ãƒšãƒ¼ã‚¸æ•°", data['summary']['total_pages'])
with col2:
    st.metric("åç›ŠåŒ–ãƒšãƒ¼ã‚¸", data['summary']['monetization_pages'])
with col3:
    st.metric("ãƒ•ã‚£ãƒ¼ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸", data['summary']['feeder_pages'])
with col4:
    st.metric("ç·åºƒå‘Šãƒªãƒ³ã‚¯æ•°", data['summary']['total_ad_links'])

# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚°ãƒ©ãƒ•
st.header("ğŸ•¸ï¸ ãƒªãƒ³ã‚¯æ§‹é€ ã®å¯è¦–åŒ–")

if len(filtered_pages) == 0:
    st.warning("âš ï¸ è¡¨ç¤ºã™ã‚‹ãƒšãƒ¼ã‚¸ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
else:
    # NetworkXã‚°ãƒ©ãƒ•ä½œæˆ
    G = nx.DiGraph()
    
    # ãƒãƒ¼ãƒ‰è¿½åŠ 
    for page in filtered_pages:
        G.add_node(
            page['url'],
            title=page.get('title', page.get('h1', page['url'])),
            type=page['type'],
            inbound_count=page['inbound_count']
        )
    
    # ã‚¨ãƒƒã‚¸è¿½åŠ 
    url_set = set(p['url'] for p in filtered_pages)
    for page in filtered_pages:
        for link in page['internal_links']:
            if link in url_set:
                G.add_edge(page['url'], link)
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨ˆç®—
    pos = nx.spring_layout(G, k=2, iterations=50)
    
    # Plotlyã‚°ãƒ©ãƒ•ä½œæˆ
    edge_trace = []
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        edge_trace.append(
            go.Scatter(
                x=[x0, x1, None],
                y=[y0, y1, None],
                mode='lines',
                line=dict(width=0.5, color='#888'),
                hoverinfo='none',
                showlegend=False
            )
        )
    
    # ãƒãƒ¼ãƒ‰ãƒˆãƒ¬ãƒ¼ã‚¹
    node_x = []
    node_y = []
    node_text = []
    node_color = []
    node_size = []
    
    color_map = {
        'monetization': '#84fab0',
        'feeder': '#a1c4fd',
        'hybrid': '#ffecd2'
    }
    
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        
        node_data = G.nodes[node]
        title = node_data['title']
        # ãƒ›ãƒãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’ç°¡æ½”ã«ï¼ˆã‚¯ãƒªãƒƒã‚¯å¯èƒ½ã«ã™ã‚‹ãŸã‚ï¼‰
        short_title = title[:30] + '...' if len(title) > 30 else title
        node_text.append(f"{short_title}<br>è¢«ãƒªãƒ³ã‚¯: {node_data['inbound_count']}")
        node_color.append(color_map[node_data['type']])
        node_size.append(max(10, min(50, node_data['inbound_count'] * 2)))
    
    # ãƒãƒ¼ãƒ‰ã®URLé †åºã‚’ä¿å­˜ï¼ˆã‚¯ãƒªãƒƒã‚¯æ™‚ã«ä½¿ç”¨ï¼‰
    node_urls_list = list(G.nodes())
    
    node_trace = go.Scatter(
        x=node_x,
        y=node_y,
        mode='markers',
        hoverinfo='text',  # ãƒ›ãƒãƒ¼æœ‰åŠ¹åŒ–
        text=node_text,
        customdata=node_urls_list,
        marker=dict(
            size=node_size,
            color=node_color,
            line=dict(width=2, color='#333')
        ),
        showlegend=False
    )
    
    # ã‚°ãƒ©ãƒ•è¡¨ç¤º
    fig = go.Figure(
        data=edge_trace + [node_trace],
        layout=go.Layout(
            showlegend=False,
            hovermode='closest',  # ãƒ›ãƒãƒ¼æœ‰åŠ¹
            margin=dict(b=0, l=0, r=0, t=0),
            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
            height=600,
            plot_bgcolor='#fafbfc'
        )
    )
    
    # ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼ˆã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆæœ‰åŠ¹ï¼‰
    st.plotly_chart(fig, use_container_width=True, on_select="rerun", key="network_graph")
    
    # ã‚¯ãƒªãƒƒã‚¯æƒ…å ±ã‚’session_stateã‹ã‚‰å–å¾—
    clicked_page = None
    if 'network_graph' in st.session_state:
        selection_data = st.session_state['network_graph']
        if selection_data and 'selection' in selection_data:
            # point_indicesã‚’ä½¿ç”¨
            point_indices = selection_data['selection'].get('point_indices', [])
            if point_indices and len(point_indices) > 0:
                point_index = point_indices[0]
                if point_index < len(node_urls_list):
                    clicked_url = node_urls_list[point_index]
                    clicked_page = next((p for p in filtered_pages if p['url'] == clicked_url), None)
    
    # ã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
    if clicked_page:
        st.markdown("---")
        st.markdown(f"### ğŸ¯ é¸æŠä¸­ã®ãƒšãƒ¼ã‚¸")
        
        col1, col2 = st.columns([3, 1])
        with col1:
            st.markdown(f"**{clicked_page.get('title', clicked_page.get('h1', 'ãƒšãƒ¼ã‚¸'))}**")
            st.caption(clicked_page['url'])
        with col2:
            # è©³ç´°ã‚’é–‹ããƒœã‚¿ãƒ³
            if st.button("ğŸ“‹ è©³ç´°ã‚’è¦‹ã‚‹", key="show_detail_btn", use_container_width=True):
                st.session_state['selected_url'] = clicked_page['url']
                st.rerun()
        
        # ç°¡æ˜“çµ±è¨ˆ
        col_stat1, col_stat2, col_stat3 = st.columns(3)
        with col_stat1:
            st.metric("è¢«ãƒªãƒ³ã‚¯", clicked_page['inbound_count'])
        with col_stat2:
            st.metric("å†…éƒ¨ãƒªãƒ³ã‚¯", len(clicked_page['internal_links']))
        with col_stat3:
            st.metric("åºƒå‘Š", len(clicked_page['ad_links']))
        st.markdown("---")
    
    # å‡¡ä¾‹ã¨èª¬æ˜
    col_legend1, col_legend2, col_legend3 = st.columns(3)
    with col_legend1:
        st.markdown("ğŸŸ¢ **åç›ŠåŒ–ãƒšãƒ¼ã‚¸** - æœ€ã‚‚é‡è¦ãªãƒšãƒ¼ã‚¸")
    with col_legend2:
        st.markdown("ğŸ”µ **ãƒ•ã‚£ãƒ¼ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸** - ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’èª˜å°")
    with col_legend3:
        st.markdown("ğŸŸ  **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰** - ä¸¡æ–¹ã®ç‰¹æ€§")
    
    st.caption("ğŸ’¡ ãƒãƒ¼ãƒ‰ã‚’ã‚¯ãƒªãƒƒã‚¯ â†’ è©³ç´°ãƒœã‚¿ãƒ³ã§å±•é–‹ | ãƒã‚¦ã‚¹ã‚’ä¹—ã›ã‚‹ã¨æƒ…å ±è¡¨ç¤º")
    
    # ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ’ãƒ³ãƒˆ
    st.info("ğŸ“‹ **è©³ç´°ã‚’è¦‹ã‚‹ã«ã¯ï¼š** ã‚°ãƒ©ãƒ•ã®ãƒãƒ¼ãƒ‰ã‚’ã‚¯ãƒªãƒƒã‚¯ â†’ è©³ç´°ãƒœã‚¿ãƒ³ | ã¾ãŸã¯ä¸‹ã®ä¸€è¦§ã§ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚¯ãƒªãƒƒã‚¯")


# ãƒšãƒ¼ã‚¸ä¸€è¦§
st.header("ğŸ“„ ãƒšãƒ¼ã‚¸è©³ç´°ãƒªã‚¹ãƒˆ")

# ãƒšãƒ¼ã‚¸é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã€Œå…¨ã¦è¡¨ç¤ºã€ï¼‰
page_urls = ['__all__'] + [p['url'] for p in filtered_pages]
page_options = {
    '__all__': 'ğŸ“‹ å…¨ãƒšãƒ¼ã‚¸ä¸€è¦§ã‚’è¡¨ç¤º',
    **{p['url']: p.get('title', p.get('h1', p['url'])) for p in filtered_pages}
}

# session_stateã‹ã‚‰ç¾åœ¨ã®é¸æŠã‚’å–å¾—ï¼ˆãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§å¤‰æ›´ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰
current_selection = st.session_state.get('selected_url', '__all__')

# ç¾åœ¨ã®é¸æŠãŒpage_urlsã«ãªã„å ´åˆï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¤‰æ›´æ™‚ãªã©ï¼‰ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«æˆ»ã™
if current_selection not in page_urls:
    current_selection = '__all__'

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®š
default_index = page_urls.index(current_selection) if current_selection in page_urls else 0

selected_page_url = st.selectbox(
    "ãƒšãƒ¼ã‚¸ã‚’é¸æŠã—ã¦ãã ã•ã„",
    page_urls,
    index=default_index,
    format_func=lambda url: page_options[url],
    key='page_selector'
)

# ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã®é¸æŠã‚’session_stateã«ä¿å­˜
st.session_state['selected_url'] = selected_page_url

# å…¨ãƒšãƒ¼ã‚¸ä¸€è¦§è¡¨ç¤º
if selected_page_url == '__all__':
    st.subheader(f"ğŸ“‹ å…¨ãƒšãƒ¼ã‚¸ä¸€è¦§ï¼ˆ{len(filtered_pages)}ãƒšãƒ¼ã‚¸ï¼‰")
    st.info("ğŸ’¡ ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦å±•é–‹ã™ã‚‹ã¨ã€è©³ç´°æƒ…å ±ï¼ˆå†…éƒ¨ãƒªãƒ³ã‚¯ã€åºƒå‘Šãƒªãƒ³ã‚¯ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãªã©ï¼‰ãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
    
    # ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    type_labels = {
        'monetization': 'ğŸ’° åç›ŠåŒ–ãƒšãƒ¼ã‚¸',
        'feeder': 'ğŸ“ ãƒ•ã‚£ãƒ¼ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸',
        'hybrid': 'ğŸ”„ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰'
    }
    
    for page_type in ['monetization', 'feeder', 'hybrid']:
        pages_of_type = [p for p in filtered_pages if p['type'] == page_type]
        if pages_of_type:
            st.markdown(f"### {type_labels[page_type]} ({len(pages_of_type)})")
            
            # ã‚«ãƒ¼ãƒ‰å½¢å¼ã§è¡¨ç¤ºï¼ˆå±•é–‹å¯èƒ½ï¼‰
            for page in pages_of_type:
                title = page.get('title', page.get('h1', page['url']))
                
                # å±•é–‹å¯èƒ½ãªã‚«ãƒ¼ãƒ‰
                with st.expander(f"**{title}** | è¢«ãƒªãƒ³ã‚¯:{page['inbound_count']} | å†…éƒ¨:{len(page['internal_links'])} | åºƒå‘Š:{len(page['ad_links'])}", expanded=False):
                    # ãƒšãƒ¼ã‚¸è©³ç´°
                    st.markdown(f"**URL:** [{page['url']}]({page['url']})")
                    
                    # çµ±è¨ˆ
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("è¢«ãƒªãƒ³ã‚¯æ•°", page['inbound_count'])
                    with col2:
                        st.metric("å†…éƒ¨ãƒªãƒ³ã‚¯æ•°", len(page['internal_links']))
                    with col3:
                        st.metric("åºƒå‘Šãƒªãƒ³ã‚¯æ•°", len(page['ad_links']))
                    
                    # Ahrefsã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                    if page['url'] in ahrefs_data:
                        st.markdown("#### ğŸ¯ ä¸Šä½ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ20ä½ä»¥å†…ï¼‰")
                        keywords = ahrefs_data[page['url']]
                        
                        keyword_html = ""
                        for kw in keywords[:20]:
                            rank_class = "rank-1-10" if kw['Current position'] <= 10 else "rank-11-20"
                            keyword_html += f'<span class="keyword-badge {rank_class}">' \
                                          f'<strong>{kw["Current position"]}ä½</strong> ' \
                                          f'{kw["Keyword"]} ({kw["Volume"]})</span> '
                        
                        st.markdown(keyword_html, unsafe_allow_html=True)
                    
                    # å†…éƒ¨ãƒªãƒ³ã‚¯
                    if page['internal_links']:
                        st.markdown("#### ğŸ”— å†…éƒ¨ãƒªãƒ³ã‚¯")
                        
                        link_data = []
                        for link in page['internal_links'][:20]:
                            linked_page = next((p for p in data['pages'] if p['url'] == link), None)
                            link_title = linked_page.get('title', linked_page.get('h1', link)) if linked_page else link.split('/')[-1]
                            link_data.append({'ã‚¿ã‚¤ãƒˆãƒ«': link_title, 'URL': link})
                        
                        df_links = pd.DataFrame(link_data)
                        st.dataframe(df_links, use_container_width=True, hide_index=True)
                    
                    # åºƒå‘Šãƒªãƒ³ã‚¯
                    if page['ad_links']:
                        st.markdown("#### ğŸ’° åºƒå‘Šãƒªãƒ³ã‚¯")
                        df_ads = pd.DataFrame([
                            {'ãƒ†ã‚­ã‚¹ãƒˆ': ad.get('text', 'ãƒªãƒ³ã‚¯'), 'ã‚¿ã‚¤ãƒ—': ad['type']}
                            for ad in page['ad_links'][:10]
                        ])
                        st.dataframe(df_ads, use_container_width=True, hide_index=True)


# å€‹åˆ¥ãƒšãƒ¼ã‚¸è©³ç´°è¡¨ç¤º
elif selected_page_url:
    page = next(p for p in filtered_pages if p['url'] == selected_page_url)
    
    # ãƒšãƒ¼ã‚¸è©³ç´°
    st.subheader(f"ğŸ” {page.get('title', page.get('h1', 'ãƒšãƒ¼ã‚¸è©³ç´°'))}")
    
    # ãƒãƒƒã‚¸
    type_labels = {
        'monetization': 'åç›ŠåŒ–ãƒšãƒ¼ã‚¸',
        'feeder': 'ãƒ•ã‚£ãƒ¼ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸',
        'hybrid': 'ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰'
    }
    st.markdown(f"**ã‚¿ã‚¤ãƒ—:** `{type_labels[page['type']]}`")
    st.markdown(f"**URL:** [{page['url']}]({page['url']})")
    
    # çµ±è¨ˆ
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("è¢«ãƒªãƒ³ã‚¯æ•°", page['inbound_count'])
    with col2:
        st.metric("å†…éƒ¨ãƒªãƒ³ã‚¯æ•°", len(page['internal_links']))
    with col3:
        st.metric("åºƒå‘Šãƒªãƒ³ã‚¯æ•°", len(page['ad_links']))
    
    # Ahrefsã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    if page['url'] in ahrefs_data:
        st.markdown("### ğŸ¯ ä¸Šä½ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆ20ä½ä»¥å†…ï¼‰")
        keywords = ahrefs_data[page['url']]
        
        keyword_html = ""
        for kw in keywords[:20]:
            rank_class = "rank-1-10" if kw['Current position'] <= 10 else "rank-11-20"
            keyword_html += f'<span class="keyword-badge {rank_class}">' \
                          f'<strong>{kw["Current position"]}ä½</strong> ' \
                          f'{kw["Keyword"]} ({kw["Volume"]})</span> '
        
        st.markdown(keyword_html, unsafe_allow_html=True)
    
    # å†…éƒ¨ãƒªãƒ³ã‚¯
    if page['internal_links']:
        st.markdown("### ğŸ”— å†…éƒ¨ãƒªãƒ³ã‚¯")
        
        # ãƒªãƒ³ã‚¯å…ˆã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—
        link_data = []
        for link in page['internal_links'][:20]:
            linked_page = next((p for p in data['pages'] if p['url'] == link), None)
            title = linked_page.get('title', linked_page.get('h1', link)) if linked_page else link.split('/')[-1]
            link_data.append({'ã‚¿ã‚¤ãƒˆãƒ«': title, 'URL': link})
        
        df_links = pd.DataFrame(link_data)
        st.dataframe(df_links, use_container_width=True, hide_index=True)
    
    # åºƒå‘Šãƒªãƒ³ã‚¯
    if page['ad_links']:
        st.markdown("### ğŸ’° åºƒå‘Šãƒªãƒ³ã‚¯")
        df_ads = pd.DataFrame([
            {'ãƒ†ã‚­ã‚¹ãƒˆ': ad.get('text', 'ãƒªãƒ³ã‚¯'), 'ã‚¿ã‚¤ãƒ—': ad['type']}
            for ad in page['ad_links'][:10]
        ])
        st.dataframe(df_ads, use_container_width=True, hide_index=True)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown(
    '<p style="text-align: center; color: #6c757d;">Made with â¤ï¸ for SEO analysis | '
    '<a href="https://github.com/ty307407-commits/FUNDiT" target="_blank">GitHub</a></p>',
    unsafe_allow_html=True
)
